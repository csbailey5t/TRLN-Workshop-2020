{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bittrlnworkshop2020virtualenv3d7570ac459b45329af28755a1ebad02",
   "display_name": "Python 3.8.0 64-bit ('TRLN-Workshop-2020': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Custom Discovery for Digitized Collections Using Computational Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "As we move through the workshop, make note of places in the process where an expert is required or needed to make the computational methods worthwhile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic modeling\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.io import output_file, output_notebook, save, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import viridis\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# general utility\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the corpus and determining approaches\n",
    "\n",
    "Let's begin by just taking a look at some of the individual OCR files to get a sense of what they might be like. We could look at the items by way of the Libraries' website, but anytime I'm doing text analysis work, I like to see the text I'll be working with directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1006\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['texts/mc00456-001-bx0004-043-001.txt',\n 'texts/mc00456-001-bx0004-053-001.txt',\n 'texts/mc00344-001-lb0001_26-002-000.txt',\n 'texts/mc00456-001-bx0007-015-001.txt',\n 'texts/mc00456-001-bx0007-005-001.txt']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "fns = glob.glob(\"texts/*.txt\")\n",
    "print(len(fns))\n",
    "fns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "THE MORAL ASPECT\nVIVISECTION.\n\nB Y\n\nE. JANE VVHATELY.\n\nIT is sometimes well for the instruction and encouraga\nment of those who give serious thought to the question\nof Vivisection, to recall the words of persons eminent for\nhigh qualities of intellect and of moral character, who\nhave passed judgment upon it. Miss E. Jane VVhately\n\ndaughter of Archbishop VVhately—was respected, trusted,\n\n. . . ’-\nand loved in no common degree by a large olrcle of friends\n\nand acquaintances.\n\nIn the preface to a short memoir of her, by her sister,\npublished in 1893, there is the following tribute to her\nworth from the pen of the well-known author of “The\nSchijnberg—Gotta Family” : “If I were to fix on one quality\nas especially characteristic of her, it would be truth—\ntruth of perception, which rested on entire truthfulness\nof character. She was true to the core in mind and\nheart. True, because she was clear-sighted, candid to\nacknowledge difﬁculties in thought or memory, and\ntherefore tolerant to differences of thought ; true, because\nin practice no shadow of self-interest ever dimmed her\nperception of what was just, or ever made her swerve\nfrom what she felt to be truest and noblest; true,\nbecause she hated exaggerations —‘ the falsehood of\nextremes’;——- true, because she was ‘a woman of a\nas those who knew her longest, and\n\n’\n\nsteadfast heart,\nthrough most vicissitudes, best knew.”\n\n[P.T.o.\n\n \n\n\n\n\n \n\n2\n\nNow let us read, in her own words, her view of\nVivisection from the standpoint of morality :-——\n\nIn reading the late correspondence between the advo-\ncates and the opponents of Vivisecti-on in The Timesﬁ“ it\nhas struck me that our friends sometimes weaken their own\ncause by bringing the chief weight of their argument to\nbear on the question whether the discoveries made by the\n“savage science,” as it has been well called, have really\nled to results which have done good service in curing or\nalleviating disease. The sharp discussion which has taken\nplace over the case of the poor man whose life was not\nsaved by an operation for brain disease, shows that the\nVivisectionists are not very amply provided with examples\neven on their side.\n\nBut is not this unsafe ground to take in arguing with\nthem? It amounts to a practical acknowledgment that if\na certain number of successful cases, resulting from their\npractice, could be found, the victory must be yielded to\nthem.\n\nNow, it seems to me that the ground that conscientious,\nnot to say God—fearing people should take, is this: Even\ngranting the results to be as productive of advantage as\ntheir most zealous advocates would contend, still we have\nno right to take an immoral course to obtain them.\n\nIt is on this ground we now blame the advocates of\nthe Inquisition. They took precisely the position in question.\nThey probably honestly believed that the doctrines, the\nspread of which they opposed, would do greater harm to\nmen’s souls than the most deadly disease to their bodies;\nand they honestly thought the best way to stop the spread\nof these opinions was their system of secret spies, torture,\nand execution of obstinate offenders. Of course in our\nenlightened days few would admit either of these premises;\n\nbut even granting them—granting that the use of reason\n\nand intelligence produced deadly harm, and that the rack\nand the dungeon were the most effectual remedy, should\nwe now admit that they were right in what they did? No,\n\nwe should say no possible good in the end could justify\nsuch means.\n\n \n\n* “Brain Surgery.”~—1884.\n\n\n\n\n3\n\nIt is quite conceivable, now, that we might stop some\ndangerous conspiracies against the safety of the whole\ncommunity by opening letters, breaking locks, and sending\nspies right and left into private houses; but we hold that\nexcept in cases where, so to speak, war has been declared,\nand fair warning given, such means would be unlawful.\nIn short, those whose standard of rectitude is high, agree\nthat immoral means must never be allowed, even for the\nbest ends. On this ground, then, the enemies of Vivisection\nmay entrench themselves, and no opponent can dislodge\nthem.\n\nAnd if it be objected to this, that we are thereby\ngiving up all hopes of making valuable discoveries in\ncertain departments of science, we may conﬁdently reply\nthat cutting off one unlawful way of attaining our object\nwill not shut out other ways of gaining it: quite the\ncontrary. If necessity is the mother of invention we may\nalso affirm that nothing quickens the intelligence, or stimu-\nlates the search for resources, like a stern and consistent\nallegiance to duty. He who will not take a crooked way\nto his goal will search till he ﬁnds a straight way, and he\nwill ﬁnd it is the best after all. The easiest way is\ncommonly the immmoral one. The simplest way for a\npoor man to satisfy his hunger is to steal; but if he is\nresolved he will not use the unlawful way, he will look\nout for lawful ones, and probably ﬁnd better ones. The\nsimplest way for a Government to get money is that\nof the Asiatic despots, by wholesale robbery and violence;\nbut a just ruler will study and labour to attain the end\nrightfully. And so those who resolve once for all that\nnone but humane and lawful means shall be used for\nphysiological discoveries, will, if they intelligently and\nheartily set to work, ﬁnd means to attain their object,\nand probably better and more reliable means. Close\nobservation of living subjects may prove more effective\nthan cruelties to creatures of another class. I believe\nit will be found here, as in other cases, that where\nthe righteous way is ﬁrst sought, “‘ all these things will\n. be added to us.”\n\n \n\n“ Guardian” General Printing Works, Manchester, Reddish, and London.\n\n \n\n\n\n\n \n\n\n\n\n\n"
    }
   ],
   "source": [
    "with open(fns[0], 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see in this text? Does the OCR look good? Are there parts of the text that you think shouldn't be included in a model that helps with discovering texts?\n",
    "\n",
    "Try picking a different file and reading through it with the same questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we now a bit about what types of texts we have, what goals would you have in providing discovery for this collection? What aspects of the documents would you want to focus on to expose to scholars?\n",
    "\n",
    "One of the main advantages of using any sort of machine learning process is that we can show relationships between and features of the items in a collection that we had not otherwise known or shown. The types of features could vary greatly. Maybe we want to show relationships based on the content of the documents in some cases. Maybe we want to expose something in the metadata of the documents. We might want to do both. \n",
    "\n",
    "Here we're going to focus on the content, and specifically one type of model that allows us to make connections across the collection: topic modeling. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is topic modeling?\n",
    "\n",
    "According to [David Blei](http://www.cs.columbia.edu/~blei/topicmodeling.html), topic models are a \"suite of algorithms that uncover the hidden thematic structure in document collections.\" Topic models operate on the idea that for any given document collection, or corpus, there is a finite number of themes, or topics, from which the corpus draws and each document is composed of words that are associated with some number of those topics. While we don't necessarily think of an author simply dipping into buckets (topics) of words and putting them together to create a document, it's turned out to be a useful model for understanding collections of documents according to the themes that cut across the collection.\n",
    "\n",
    "There are quite a few types of topic models, but we'll focus on one of the most common forms: latent dirichlet allocation (LDA). LDA topic modeling is a form of unsupervised machine learning, wherein we provide an unlabeled corpus of texts to the algorithm, which then produces the model, though we often provide the number of topics that the algorithm should use for the model. While there are processes for determining the \"correct\" number of topics, many consider this part of topic modeling a bit of an art that is determined as much by the research questions of the person running the model as it is by the corpus and model. Other types of topic models highlight different aspects and problematics of types of corpora, such as temporal differentiation and author bias. \n",
    "\n",
    "A topic model gives us a number of data objects. We'll have a list of topics, which are distributions over terms, though we could think of topics somewhat simply as sets of regularly co-occuring terms. We'll also have a representation of each document in the corpus as a vector denoting the composition of the document according to the topics, that is, we'll have an account of how much of each document is associated with each topic. \n",
    "\n",
    "Key resource: [Probabilistic Topic Models](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf) by David Blei. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other models or approaches that could be useful for discovery\n",
    "\n",
    "- Keyword extraction\n",
    "- Automated summarization\n",
    "- Entity extraction, including geospatial data\n",
    "- Various clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the corpus\n",
    "\n",
    "Now that we know what type of model, we'll use, let's jump in to building hte model itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in and cleaning the documents\n",
    "\n",
    "How we're going to read in and clean our texts is somewhat particular to `gensim`, the library we're using for our topic model. You could absolutely approach this part of the process in different ways, but we'll stick with an approach recommended by the author of `gensim` so that if you're looking for documentation and help later, it will be easier to find. For this part we'll hew closely to the code in the following tutorial.\n",
    "\n",
    "[Radim Řehůřek's topic modeling tutorial](https://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since corpora can be large, it's often a good idea to approach reading in data with streaming in mind. Rather than reading in all of our data at once and then processing it, we'll read it each item in and process it one at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(stream, n=10):\n",
    "    \"\"\"Given a stream of data items, return just the first n as a list\"\"\"\n",
    "    return list(itertools.islice(stream, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We currently have filenames that include the item id. We'll want to associate the processed texts with just item id, so we need to pull it out of the filename.\n",
    "def get_item_id(fn):\n",
    "    \"\"\"Given a filename, return just the item id\"\"\"\n",
    "    return os.path.split(fn)[1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning texts is often iterative, and how much you clean your corpus depends on the model you use. For topic modeling, I typically start without cleaning at all, get results, then piece by piece add in the minimum necessary cleaning to get sensible results. What we'll do in the function below is based on that minimal approach. \n",
    "\n",
    "Just due to how `gensim` builds corpora for processing, we need to break each text down into its component tokens, which in this case are just the individual words of the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Given a text, tokenize it while removing stopwords, non-alpha characters, and one letter words\"\"\"\n",
    "    tokens = [token for token in word_tokenize(text) if token.lower() not in STOPWORDS]\n",
    "    cleaned = [token for token in tokens if token.isalpha()]\n",
    "    cleaned_greater_1 = [token for token in cleaned if len(token) > 1]\n",
    "    return cleaned_greater_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_stream(text_dir):\n",
    "    \"\"\"Given a directory of plain text files, return a stream of tuples with the item id from the filename and the cleaned, tokenized text\"\"\"\n",
    "    for fn in glob.glob(f\"{text_dir}/*.txt\"):\n",
    "        item_id = get_item_id(fn)\n",
    "        with open(fn, 'r') as f:\n",
    "            document = f.read()\n",
    "            yield(item_id, tokenize(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've defined all the functions we need to read in our documents and process them. We'll use the `head` utility function we wrote above to look at the first file and see how well our processing worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('mc00456-001-bx0004-043-001',\n  ['MORAL',\n   'ASPECT',\n   'VIVISECTION',\n   'JANE',\n   'VVHATELY',\n   'instruction',\n   'encouraga',\n   'ment',\n   'thought',\n   'question',\n   'Vivisection',\n   'recall',\n   'words',\n   'persons',\n   'eminent',\n   'high',\n   'qualities',\n   'intellect',\n   'moral',\n   'character',\n   'passed',\n   'judgment',\n   'Miss',\n   'Jane',\n   'VVhately',\n   'daughter',\n   'Archbishop',\n   'respected',\n   'trusted',\n   'loved',\n   'common',\n   'degree',\n   'large',\n   'olrcle',\n   'friends',\n   'acquaintances',\n   'preface',\n   'short',\n   'memoir',\n   'sister',\n   'published',\n   'following',\n   'tribute',\n   'worth',\n   'pen',\n   'author',\n   'Got',\n   'ta',\n   'Family',\n   'fix',\n   'quality',\n   'especially',\n   'characteristic',\n   'truth',\n   'perception',\n   'rested',\n   'entire',\n   'truthfulness',\n   'character',\n   'true',\n   'core',\n   'mind',\n   'heart',\n   'True',\n   'candid',\n   'acknowledge',\n   'difﬁculties',\n   'thought',\n   'memory',\n   'tolerant',\n   'differences',\n   'thought',\n   'true',\n   'practice',\n   'shadow',\n   'dimmed',\n   'perception',\n   'swerve',\n   'felt',\n   'truest',\n   'noblest',\n   'true',\n   'hated',\n   'exaggerations',\n   'falsehood',\n   'extremes',\n   'true',\n   'woman',\n   'knew',\n   'longest',\n   'steadfast',\n   'heart',\n   'vicissitudes',\n   'best',\n   'let',\n   'read',\n   'words',\n   'view',\n   'Vivisection',\n   'standpoint',\n   'morality',\n   'reading',\n   'late',\n   'correspondence',\n   'cates',\n   'opponents',\n   'Timesﬁ',\n   'struck',\n   'friends',\n   'weaken',\n   'cause',\n   'bringing',\n   'chief',\n   'weight',\n   'argument',\n   'bear',\n   'question',\n   'discoveries',\n   'savage',\n   'science',\n   'called',\n   'led',\n   'results',\n   'good',\n   'service',\n   'curing',\n   'alleviating',\n   'disease',\n   'sharp',\n   'discussion',\n   'taken',\n   'place',\n   'case',\n   'poor',\n   'man',\n   'life',\n   'saved',\n   'operation',\n   'brain',\n   'disease',\n   'shows',\n   'Vivisectionists',\n   'amply',\n   'provided',\n   'examples',\n   'unsafe',\n   'ground',\n   'arguing',\n   'amounts',\n   'practical',\n   'acknowledgment',\n   'certain',\n   'number',\n   'successful',\n   'cases',\n   'resulting',\n   'practice',\n   'victory',\n   'yielded',\n   'ground',\n   'conscientious',\n   'people',\n   'granting',\n   'results',\n   'productive',\n   'advantage',\n   'zealous',\n   'advocates',\n   'contend',\n   'right',\n   'immoral',\n   'course',\n   'obtain',\n   'ground',\n   'blame',\n   'advocates',\n   'Inquisition',\n   'took',\n   'precisely',\n   'position',\n   'question',\n   'probably',\n   'honestly',\n   'believed',\n   'doctrines',\n   'spread',\n   'opposed',\n   'greater',\n   'harm',\n   'men',\n   'souls',\n   'deadly',\n   'disease',\n   'bodies',\n   'honestly',\n   'thought',\n   'best',\n   'way',\n   'stop',\n   'spread',\n   'opinions',\n   'secret',\n   'spies',\n   'torture',\n   'execution',\n   'obstinate',\n   'offenders',\n   'course',\n   'enlightened',\n   'days',\n   'admit',\n   'premises',\n   'granting',\n   'use',\n   'reason',\n   'intelligence',\n   'produced',\n   'deadly',\n   'harm',\n   'rack',\n   'dungeon',\n   'effectual',\n   'remedy',\n   'admit',\n   'right',\n   'possible',\n   'good',\n   'end',\n   'justify',\n   'means',\n   'Brain',\n   'conceivable',\n   'stop',\n   'dangerous',\n   'conspiracies',\n   'safety',\n   'community',\n   'opening',\n   'letters',\n   'breaking',\n   'locks',\n   'sending',\n   'spies',\n   'right',\n   'left',\n   'private',\n   'houses',\n   'hold',\n   'cases',\n   'speak',\n   'war',\n   'declared',\n   'fair',\n   'warning',\n   'given',\n   'means',\n   'unlawful',\n   'short',\n   'standard',\n   'rectitude',\n   'high',\n   'agree',\n   'immoral',\n   'means',\n   'allowed',\n   'best',\n   'ends',\n   'ground',\n   'enemies',\n   'Vivisection',\n   'entrench',\n   'opponent',\n   'dislodge',\n   'objected',\n   'giving',\n   'hopes',\n   'making',\n   'valuable',\n   'discoveries',\n   'certain',\n   'departments',\n   'science',\n   'conﬁdently',\n   'reply',\n   'cutting',\n   'unlawful',\n   'way',\n   'attaining',\n   'object',\n   'shut',\n   'ways',\n   'gaining',\n   'contrary',\n   'necessity',\n   'mother',\n   'invention',\n   'affirm',\n   'quickens',\n   'intelligence',\n   'lates',\n   'search',\n   'resources',\n   'like',\n   'stern',\n   'consistent',\n   'allegiance',\n   'duty',\n   'crooked',\n   'way',\n   'goal',\n   'search',\n   'till',\n   'ﬁnds',\n   'straight',\n   'way',\n   'ﬁnd',\n   'best',\n   'easiest',\n   'way',\n   'commonly',\n   'immmoral',\n   'simplest',\n   'way',\n   'poor',\n   'man',\n   'satisfy',\n   'hunger',\n   'steal',\n   'resolved',\n   'use',\n   'unlawful',\n   'way',\n   'look',\n   'lawful',\n   'ones',\n   'probably',\n   'ﬁnd',\n   'better',\n   'ones',\n   'simplest',\n   'way',\n   'Government',\n   'money',\n   'Asiatic',\n   'despots',\n   'wholesale',\n   'robbery',\n   'violence',\n   'ruler',\n   'study',\n   'labour',\n   'attain',\n   'end',\n   'rightfully',\n   'resolve',\n   'humane',\n   'lawful',\n   'means',\n   'shall',\n   'physiological',\n   'discoveries',\n   'intelligently',\n   'heartily',\n   'set',\n   'work',\n   'ﬁnd',\n   'means',\n   'attain',\n   'object',\n   'probably',\n   'better',\n   'reliable',\n   'means',\n   'Close',\n   'observation',\n   'living',\n   'subjects',\n   'prove',\n   'effective',\n   'cruelties',\n   'creatures',\n   'class',\n   'believe',\n   'cases',\n   'righteous',\n   'way',\n   'ﬁrst',\n   'sought',\n   'things',\n   'added',\n   'Guardian',\n   'General',\n   'Printing',\n   'Works',\n   'Manchester',\n   'Reddish',\n   'London'])]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "head(text_stream(text_dir), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also just look at the first or last bunch of tokens for each text to get a sense of the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mc00456-001-bx0004-043-001 ['MORAL', 'ASPECT', 'VIVISECTION', 'JANE', 'VVHATELY', 'instruction', 'encouraga', 'ment', 'thought', 'question']\nmc00456-001-bx0004-053-001 ['ecial', 'Repert', 'Emu', 'BM', 'OW', 'NATNNAL', 'ALTN', 'MEDHAL', 'CUMMWTEE', 'Repmft']\nmc00344-001-lb0001_26-002-000 ['Sydney', 'Daily', 'Telegraph', 'August', 'Cattle', 'producers', 'want', 'meat', 'eXport', 'inquiry']\nmc00456-001-bx0007-015-001 ['EDHWON', 'ABOMINABLE', 'SIN', 'Lord', 'Shaftesbury', 'VIVISECTION', 'APPEAL', 'Scientific', 'Ethical', 'Thinkers']\nmc00456-001-bx0007-005-001 ['UNSOIENTIFIC', 'VIEW', 'VIVISECTION', 'LADY', 'PAGET', 'Reprinted', 'NATIONAL', 'REVIEW', 'September', 'years']\n"
    }
   ],
   "source": [
    "for item_id, tokens in head(text_stream(text_dir), n=5):\n",
    "    print(item_id, tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "mc00456-001-bx0004-043-001 ['sought', 'things', 'added', 'Guardian', 'General', 'Printing', 'Works', 'Manchester', 'Reddish', 'London']\nmc00456-001-bx0004-053-001 ['Relations', 'Janet', 'Loud', 'Price', 'net', 'lnlh', 'll', 'lo', 'Ctltt', 'iﬁ']\nmc00344-001-lb0001_26-002-000 ['resulted', 'fewer', 'hijack', 'attempts', 'orderly', 'open', 'process', 'days', 'legislative', 'session']\nmc00456-001-bx0007-015-001 ['sectarian', 'political', 'barriers', 'appeals', 'phase', 'thought', 'Write', 'Nixon', 'page', 'cover']\nmc00456-001-bx0007-005-001 ['Cause', 'annum', 'post', 'free', 'PEWIRESS', 'PIIEte', 'LiRle', 'Queen', 'Street', 'High']\n"
    }
   ],
   "source": [
    "for item_id, tokens in head(text_stream(text_dir), n=5):\n",
    "    print(item_id, tokens[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build the model, we now actually need to break apart the pieces of data that we put together in our text_stream function: the item id and the processed text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['mc00456-001-bx0004-043-001',\n 'mc00456-001-bx0004-053-001',\n 'mc00344-001-lb0001_26-002-000',\n 'mc00456-001-bx0007-015-001',\n 'mc00456-001-bx0007-005-001',\n 'mc00344-001-bx0001_35-003-000',\n 'mc00344-001-bx0001_38-004-000',\n 'mc00456-001-bx0001-020-001',\n 'aspca-scrapbooks-bx0001-002-001_0_20191213_759',\n 'mc00344-001-bx0001_5-001-000']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# You could extract the item_ids from the full text_stream, but in order to not\n",
    "# tokenize everything when we don't yet need to we'll pull them directly from the filenames\n",
    "item_ids = [get_item_id(fn) for fn in fns]\n",
    "head(item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a generator comprehension. \n",
    "doc_stream = (tokens for _, tokens in text_stream(text_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Reflection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}